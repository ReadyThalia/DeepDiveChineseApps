## Random variable to predict #################################################

# This application's goal is to predict whether a given pair of location mention
# are indicating a affiliation relationship or not.
@extraction
has_affiliation?(
    @key
    @references(relation="location_mention", column="mention_id", alias="p1")
    p1_id text,
    @key
    @references(relation="location_mention", column="mention_id", alias="p2")
    p2_id text
).

## Input Data #################################################################

@source
articles(
    @key
    @distributed_by
    id text,
    @searchable
    content text
).

@source
positive_db(
    @key
    person1_name text,
    @key
    person2_name text
).

negative_db(
    @key
    person1_name text,
    @key
    person2_name text
).

## NLP markup #################################################################
@source
sentences(
    @key
    @distributed_by
    # XXX This breaks the search index.  @source should not be derived from another @source
    #@references(relation="articles", column="id")
    doc_id         text,
    @key
    sentence_index int,
    @searchable
    sentence_text  text,
    tokens         text[],
    lemmas         text[],
    pos_tags       text[],
    ner_tags       text[],
    doc_offsets    int[],
    dep_types      text[],
    dep_tokens     int[]
).

@data
sentences(
    @key
    @distributed_by
    # XXX This breaks the search index.  @source should not be derived from another @source
    #@references(relation="articles", column="id")
    doc_id         text,
    @key
    sentence_index int,
    @searchable
    sentence_text  text,
    tokens         text[],
    lemmas         text[],
    pos_tags       text[],
    ner_tags       text[],
    doc_offsets    int[],
    dep_types      text[],
    dep_tokens     int[]
).

function nlp_markup over (
        doc_id text,
        content text
    ) returns rows like sentences
    implementation "udf/nlp_markup.sh" handles tsv lines.

sentences += nlp_markup(doc_id, content) :-
    articles(doc_id, content).


## Candidate mapping ##########################################################
@extraction
location_mention(
    @key
    mention_id text,
    @searchable
    mention_text text,
    @distributed_by
    @references(relation="sentences", column="doc_id",         alias="appears_in")
    doc_id text,
    @references(relation="sentences", column="sentence_index", alias="appears_in")
    sentence_index int,
    begin_index int,
    end_index int
).

function map_location_mention over (
        doc_id text,
        sentence_index int,
        tokens text[],
        ner_tags text[]
    ) returns rows like location_mention
    implementation "udf/map_location_mention.py" handles tsv lines.

location_mention += map_location_mention(
    doc_id, sentence_index, tokens, ner_tags
) :- sentences(doc_id, sentence_index, _, tokens, _, _, ner_tags, _, _, _).

location_candidate(
    p1_id text,
    p1_name text,
    p2_id text,
    p2_name text
).

num_location(doc_id, sentence_index, COUNT(p)) :-
    location_mention(p, _, doc_id, sentence_index, _, _).

location_candidate(p1, p1_name, p2, p2_name) :-
    num_location(same_doc, same_sentence, num_p),
    location_mention(p1, p1_name, same_doc, same_sentence, p1_begin, _),
    location_mention(p2, p2_name, same_doc, same_sentence, p2_begin, _),
    num_p < 5,
    p1 < p2,
    p1_name != p2_name,
    p1_begin != p2_begin.


## Feature Extraction #########################################################

# Feature extraction (using DDLIB via a UDF) at the relation level
@extraction
location_features(
    @key
    @references(relation="has_affiliation", column="p1_id", alias="has_affiliation")
    p1_id text,
    @key
    @references(relation="has_affiliation", column="p2_id", alias="has_affiliation")
    p2_id text,
    @key
    feature text
).

function extract_location_features over (
        p1_id text,
        p2_id text,
        p1_begin_index int,
        p1_end_index int,
        p2_begin_index int,
        p2_end_index int,
        doc_id text,
        sent_index int,
        tokens text[],
        lemmas text[],
        pos_tags text[],
        ner_tags text[],
        dep_types text[],
        dep_tokens int[]
    ) returns rows like location_features
    implementation "udf/extract_location_features.py" handles tsv lines.

location_features += extract_location_features(
    p1_id, p2_id, p1_begin_index, p1_end_index, p2_begin_index, p2_end_index,
    doc_id, sent_index, tokens, lemmas, pos_tags, ner_tags, dep_types, dep_tokens
) :-
    location_mention(p1_id, _, doc_id, sent_index, p1_begin_index, p1_end_index),
    location_mention(p2_id, _, doc_id, sent_index, p2_begin_index, p2_end_index),
    sentences(doc_id, sent_index, _, tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_tokens).


## Distant Supervision ########################################################
@extraction
affiliation_label(
    @key
    @references(relation="has_affiliation", column="p1_id", alias="has_affiliation")
    p1_id text,
    @key
    @references(relation="has_affiliation", column="p2_id", alias="has_affiliation")
    p2_id text,
    @navigable
    label int,
    @navigable
    rule_id text
).

# make sure all pairs in location_candidate are considered as unsupervised examples
affiliation_label(p1,p2, 0, NULL) :- location_candidate(p1, _, p2, _).

# distant supervision using data from DBpedia
affiliation_label(p1,p2, 1, "from_dbpedia") :-
    location_candidate(p1, p1_name, p2, p2_name),
    positive_db(n1, n2),
    [ lower(n1) = lower(p1_name), lower(n2) = lower(p2_name)].

affiliation_label(p1,p2, -1, "from_dbpedia") :-
    location_candidate(p1, p1_name, p2, p2_name),
    negative_db(n1, n2),
    [ lower(n1) = lower(p1_name), lower(n2) = lower(p2_name)].

# supervision by heuristic rules in a UDF
function supervise over (
        p1_id text, p1_begin int, p1_end int,
        p2_id text, p2_begin int, p2_end int,
        doc_id         text,
        sentence_index int,
        sentence_text  text,
        tokens         text[],
        lemmas         text[],
        pos_tags       text[],
        ner_tags       text[],
        dep_types      text[],
        dep_tokens    int[]
    ) returns (
        p1_id text, p2_id text, label int, rule_id text
    )
    implementation "udf/supervise_affiliation.py" handles tsv lines.

affiliation_label += supervise(
    p1_id, p1_begin, p1_end,
    p2_id, p2_begin, p2_end,
    doc_id, sentence_index, sentence_text,
    tokens, lemmas, pos_tags, ner_tags, dep_types, dep_token_indexes
) :- location_candidate(p1_id, _, p2_id, _),
    location_mention(p1_id, p1_text, doc_id, sentence_index, p1_begin, p1_end),
    location_mention(p2_id, p2_text,      _,              _, p2_begin, p2_end),
    sentences(
        doc_id, sentence_index, sentence_text,
        tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_token_indexes
    ).


# resolve multiple labels by majority vote (summing the labels in {-1,0,1})
affiliation_label_resolved(p1_id, p2_id, SUM(vote)) :- affiliation_label(p1_id, p2_id, vote, rule_id).

# assign the resolved labels for the affiliation relation
has_affiliation(p1_id, p2_id) = if l > 0 then TRUE
                      else if l < 0 then FALSE
                      else NULL end :- affiliation_label_resolved(p1_id, p2_id, l).

###############################################################################

## Inference Rules ############################################################

# Features
@weight(f)
has_affiliation(p1_id, p2_id) :-
    location_candidate(p1_id, _, p2_id, _),
    location_features(p1_id, p2_id, f).

# Inference rule: Continuous
@weight(1.0)
has_affiliation(p1_id, p2_id) => has_affiliation(p1_id, p3_id) :-
    has_affiliation(p2_id,p3_id).

@weight(-0.5)
has_affiliation(p1_id, p2_id) => has_affiliation(p2_id, p1_id) :-
    location_candidate(p1_id, _, p2_id, _).
